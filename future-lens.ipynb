{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Lens reimplementation\n",
    "\n",
    "Based on \"Anticipating Subsequent Tokens from a Single Hidden State\" (\n",
    "https://future.baulab.info/ )\n",
    "\n",
    "In the original paper, they try four implementations.\n",
    "t_n_l = state at token t position n layer l (of L):\n",
    "1. Linear map from hidden state t_n_l to final state t_n+1_L\n",
    "2. Linear map from hidden state t_n_l to token t_n+1 logits\n",
    "3. Transfer of hidden state t_n_l to new prompt, and generate\n",
    "4. Transfer of hidden state t_n_l to pseudo-prompt consisting of fine-tuned\n",
    "  embedding inputs\n",
    "\n",
    "I limit my analysis to mostly just 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c16143ec33463fbf540b42ad666953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model 'microsoft/phi-3-mini-4k-instruct' with bfp16:\n",
      "- Added 512 hooks across 32 layers\n"
     ]
    }
   ],
   "source": [
    "# Define and load model\n",
    "import torch\n",
    "from taker import Model\n",
    "\n",
    "m = Model(\"microsoft/phi-3-mini-4k-instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transfer of hidden state to new prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Before\n",
      "Info prompt      : ('Madison Square Garden is located in', ' New York City. The largest zoo in the world')\n",
      "Neutral prompt   : ('Tell me something about', ' your hobbies and interests. (2)')\n",
      "Neutral prompt   : ('Tell me something about', ' me, based on my shopping list. I')\n",
      "Neutral prompt   : ('Tell me something about', ' the life of a poet.\\n\\n# Po')\n",
      "# After\n",
      "Transferred acts : ('Tell me something about', \" New York City that's interesting to tourists\")\n",
      "Transferred acts : ('Tell me something about', ' New York.\\n\\n## Response:New York')\n",
      "Transferred acts : ('Tell me something about', \" New York City. I'm feeling adventur\")\n"
     ]
    }
   ],
   "source": [
    "info_prompt    = \"Madison Square Garden is located in\"\n",
    "neutral_prompt = \"Tell me something about\"\n",
    "\n",
    "# Reset model to not replace any activations\n",
    "m.hooks.reset_neuron_replace()\n",
    "\n",
    "# before modifications\n",
    "print(\"# Before\")\n",
    "print(\"Info prompt      :\", m.generate(info_prompt))\n",
    "for i in range(3):\n",
    "    print(\"Neutral prompt   :\", m.generate(neutral_prompt))\n",
    "\n",
    "#Â Find where to position token insertions\n",
    "orig_token_index = m.get_ids(info_prompt).shape[1] - 1\n",
    "new_token_index  = m.get_ids(neutral_prompt).shape[1] - 1\n",
    "\n",
    "# transplant information activations\n",
    "# NOTE: doesn't seem to work well with single state transfer. Better with multiple\n",
    "acts = m.get_midlayer_activations(info_prompt)\n",
    "\n",
    "for layer_index in range(10, 20):\n",
    "    m.hooks.neuron_replace[f\"layer_{layer_index}_mlp_pre_out\"].add_token(new_token_index, acts[\"mlp\"][0, layer_index, orig_token_index])\n",
    "    m.hooks.neuron_replace[f\"layer_{layer_index}_attn_pre_out\"].add_token(new_token_index, acts[\"attn\"][0, layer_index, orig_token_index])\n",
    "\n",
    "# generate a few samples\n",
    "print(\"# After\")\n",
    "for i in range(3):\n",
    "    print(\"Transferred acts :\", m.generate(neutral_prompt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
